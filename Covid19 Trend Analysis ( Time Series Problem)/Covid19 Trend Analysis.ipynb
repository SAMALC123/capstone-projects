{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f098c3c4",
   "metadata": {},
   "source": [
    "# PRCP-1023-JohnsHopkinsCovid19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d118c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb07e89d",
   "metadata": {},
   "source": [
    "Corona Virus disease (COVID-19) is an infectious disease caused by a newly discovered virus, which emerged in Wuhan, China in December of 2019.Most people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness. The COVID-19 virus spreads primarily through droplets of saliva or discharge from the nose when an infected person coughs or sneezes, so you might have heard caution to practice respiratory etiquette  The artificial intelligence researchers are focusing their expertise knowledge to develop mathematical models for analyzing this epidemic situation using nationwide shared data. To contribute towards the well-being of living society, this project proposes to utilize the machine learning and models with the aim for understanding its everyday exponential behaviour along with the prediction of future reachability of the COVID-2019 across the nations by utilizing the real-time information from the Johns Hopkins dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1753c",
   "metadata": {},
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e7aa644",
   "metadata": {},
   "source": [
    "The day to day prevalence data of COVID-2019 from January 22, 2020, to September 21, 2020, were retrieved from the official repository of Johns Hopkins University. The dataset consists of daily case reports and daily time series summary tables. In the present study, we have taken time-series summary tables in CSV format having three tables for confirmed, death and recovered cases of COVID-2019 with six attributes i.e. province/state, country/region, last update, confirmed, death and recovered cases, where the update frequency of the dataset is once in a day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867fb5a",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be27935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a69c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d250d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"jupyterlab>=3\" \"ipywidgets>=7.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610909b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install jupyter-dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2e2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotly_express==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54b8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60eb9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d50e81",
   "metadata": {},
   "source": [
    "# Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417430f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'confirmed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m confirmed\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfirmed.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m deaths\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeaths.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m recovered\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecovered.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'confirmed.csv'"
     ]
    }
   ],
   "source": [
    "confirmed=pd.read_csv(\"confirmed.csv\")\n",
    "deaths=pd.read_csv(\"deaths.csv\")\n",
    "recovered=pd.read_csv(\"recovered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d87d4",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d9ddf",
   "metadata": {},
   "source": [
    "### Confirmed Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062a879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daabf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69febf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a761be",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0223792",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39266fc3",
   "metadata": {},
   "source": [
    "### Death Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4802b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85298de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deaths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4566c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc71072",
   "metadata": {},
   "source": [
    "### Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fa093",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99488b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a3e9e",
   "metadata": {},
   "source": [
    "## Insights "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e91e138",
   "metadata": {},
   "source": [
    "3 Tables are pretty much similar, with same no of columns also.\n",
    "Datas are available from 22 January 2020 to 21 September 2020\n",
    "A lots of Nan values can see in Province/State tables\n",
    "From the data we can understand which are the dates where each country first confirmed,deaths and recovery happens\n",
    "From the data understood that more than 6M(million) confirmed cases happens, nearly .2M deaths and nearly 4.4M recovery also happens \n",
    "For the better understanding and more clarity we have to do Data Visualization. Then only we can understand which country affected badly which country survived and much more related things regarding Covid 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b702bd9",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ef821b4",
   "metadata": {},
   "source": [
    "Before doing the Data Visualization we need to fill nan values and merge the datas together for better understandings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8812dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.columns[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b7dd9",
   "metadata": {},
   "source": [
    "### Merging Confirmed,Deaths and Recovered"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d17f2d0",
   "metadata": {},
   "source": [
    "To make analysis of data in table easier, we can reshape the data into a more computer-friendly form using Pandas in Python. Pandas.melt() is one of the function to do so..\n",
    "Pandas.melt() unpivots a DataFrame from wide format to long format.\n",
    "melt() function is useful to message a DataFrame into a format where one or more columns are identifier variables, while all other columns, considered measured variables, are unpivoted to the row axis, leaving just two non-identifier columns, variable and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = confirmed.columns[4:]\n",
    "confirmed_new= confirmed.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='confirmed'\n",
    ")\n",
    "deaths_new= deaths.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='deaths'\n",
    ")\n",
    "recovered_new = recovered.melt(\n",
    "    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n",
    "    value_vars=dates, \n",
    "    var_name='Date', \n",
    "    value_name='recovered'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a830dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to remove recovered data for Canada\n",
    "#due to mismatch issue ( Canada recovered data is counted by Country-wise rather than Province/State-wise).#\n",
    "\n",
    "recovered_new = recovered_new[recovered_new['Country/Region']!='Canada']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff233b9e",
   "metadata": {},
   "source": [
    "Pandas DataFrame merge() function is used to merge two DataFrame objects with a database-style join operation. The joining is performed on columns or indexes. If the joining is done on columns, indexes are ignored. This function returns a new DataFrame and the source DataFrame objects are unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use merge() to merge the 3 DataFrames one after another\n",
    "\n",
    "# Merging confirmed_new and deaths_new\n",
    "full = confirmed_new.merge(\n",
    "  right=deaths_new, \n",
    "  how='left',\n",
    "  on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n",
    ")\n",
    "# Merging full and recovered_new\n",
    "full = full.merge(\n",
    "  right=recovered_new, \n",
    "  how='left',\n",
    "  on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ace6663f",
   "metadata": {},
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e2bef",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5defdf",
   "metadata": {},
   "source": [
    "- Convert date to string to datetime\n",
    "-  Handling Nan Values, replace with zero\n",
    "- Coronavirus cases reported from 3 cruise ships should be treated differently\n",
    "-  Date column are all string with m/dd/yy format. To convert Date values from string to datetime, let’s use DataFrame.to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead323ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let’s use DataFrame.to_datetime()\n",
    "\n",
    "full['Date'] = pd.to_datetime(full['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc313f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02d84a90",
   "metadata": {},
   "source": [
    "we merged datas together now we have to take care of nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.isna().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e78a5332",
   "metadata": {},
   "source": [
    " we got nan values in two columns Province/State and recovered\n",
    " Province and State no longer needed because we look only Country/Region\n",
    " recovered nan values replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d44389",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['recovered'] = full['recovered'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7697279d",
   "metadata": {},
   "source": [
    "we have to check datatypes of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57038361",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "292863c7",
   "metadata": {},
   "source": [
    "Apart from missing values, there are coronavirus cases reported from 3 cruise ships: Grand Princess, Diamond Princess and MS Zaandam. These data need to be extracted and treated differently due to Province/State and Country/Region mismatch over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a43d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And here is how we extract the ship data.\n",
    "\n",
    "ship_rows = full['Province/State'].str.contains('Grand Princess')|full['Province/State'].str.contains('Diamond Princess') |full['Country/Region'].str.contains('Diamond Princess') |full['Country/Region'].str.contains('MS Zaandam')\n",
    "full_ship = full[ship_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed866dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And to get rid of ship data from full_table :\n",
    "\n",
    "full = full[~(ship_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d0367",
   "metadata": {},
   "source": [
    "## Data Aggregation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c603a39",
   "metadata": {},
   "source": [
    "So far we merged all the raw data available and grouped together\n",
    "But for day today updates these table is useless, so we have to create  new column named active , which means how many still active cases are their.\n",
    "active cases also help us to understand how many are recovered and deaths ie, active = confirmed-deaths-recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b30c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Active'] = full['confirmed'] - full['deaths'] - full['recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70aad985",
   "metadata": {},
   "source": [
    "we got the table in the required format, but it still look difficult \n",
    "So we can remove some columns and keep the necessary that are beneficial for the forecasting\n",
    "sum() is to get the total count of ‘Confirmed’, ‘Deaths’, ‘Recovered’, ‘Active’ for the given Date and Country/Region.\n",
    "reset_index() reset the index and use the default one, which is Date and Country/Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new = full.groupby(['Date', 'Country/Region'])['confirmed', 'deaths', 'recovered', 'Active'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cee4952",
   "metadata": {},
   "source": [
    "Table is pretty  useful but we cannot extract all the necessary information from the table , so we have to add few columns\n",
    "Confirmed, Deaths, Recovered and Active are cumulative data.\n",
    "New cases, New deaths and New Recovered are day wise data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5356b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let’s add day wise New cases, New deaths and New recovered by deducting the corresponding accumulative data on the previous day.\n",
    "\n",
    "# new cases \n",
    "temp = full_new.groupby(['Country/Region', 'Date', ])['confirmed', 'deaths', 'recovered']\n",
    "temp = temp.sum().diff().reset_index()\n",
    "mask = temp['Country/Region'] != temp['Country/Region'].shift(1)\n",
    "temp.loc[mask, 'confirmed'] = np.nan\n",
    "temp.loc[mask, 'deaths'] = np.nan\n",
    "temp.loc[mask, 'recovered'] = np.nan\n",
    "# renaming columns\n",
    "temp.columns = ['Country/Region', 'Date', 'New cases', 'New deaths', 'New recovered']\n",
    "# merging new values\n",
    "full_new = pd.merge(full_new, temp, on=['Country/Region', 'Date'])\n",
    "# filling na with 0\n",
    "full_new = full_new.fillna(0)\n",
    "# fixing data types\n",
    "cols = ['New cases', 'New deaths', 'New recovered']\n",
    "full_new[cols] = full_new[cols].astype('int')\n",
    "# \n",
    "full_new['New cases'] = full_new['New cases'].apply(lambda x: 0 if x<0 else x)\n",
    "#And finally here is the full_grouped. Be aware of that this final output is Country-wise data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64dec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41a49c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6239c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.pie(full_new, values='confirmed',names='Country/Region',title=\"Confirmed Cases \")\n",
    "fig.update_traces(textposition=\"inside\")\n",
    "fig.update_layout(uniformtext_minsize=12,uniformtext_mode=\"hide\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f31b4b70",
   "metadata": {},
   "source": [
    "US reported more confirmed cases and it is 25% overall cases reported all over the world \n",
    "more than 50% total cases reported in  US,Brazil,India,Russia in these countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d57d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.pie(full_new, values='deaths',names='Country/Region',title=\"Mortality Cases \")\n",
    "fig.update_traces(textposition=\"inside\")\n",
    "fig.update_layout(uniformtext_minsize=12,uniformtext_mode=\"hide\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a1256dd",
   "metadata": {},
   "source": [
    "More mortality cases happens in US,Brazil,UK,Italy,Mexico,France,Spain and India\n",
    "nearly 25% mortality cases reported by US\n",
    "70% mortality cases reported by above mentioned countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b889beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(full_new, values='recovered',names='Country/Region',title=\"Recovered Cases \")\n",
    "fig.update_traces(textposition=\"inside\")\n",
    "fig.update_layout(uniformtext_minsize=12,uniformtext_mode=\"hide\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c56ee1a",
   "metadata": {},
   "source": [
    "More recovered cases in Brazil,US,India and Russia\n",
    "50% of overall recovered cases contributed by above mention countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014dabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = px.line(full_new, x='Date', y=['confirmed'], \n",
    "               title='Confirmed Cases')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54b29d79",
   "metadata": {},
   "source": [
    "Since May confirmed cases crossed 1M \n",
    "Confirmed cases increasing each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f22b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot = px.line(full_new, x='Date', y=['deaths'], \n",
    "               title='Mortality Case')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b09bc00f",
   "metadata": {},
   "source": [
    "Mortality cases significantly increaed since may and go on rising \n",
    "Since June more than 100K people dying and the count is increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = px.line(full_new, x='Date', y=['recovered'], \n",
    "               title='Recovered Case')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc429863",
   "metadata": {},
   "source": [
    "Overall It's  positive sign that since june more than 1M people recovering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb393fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = px.line(full_new, x='Date', y=['New cases'], \n",
    "               title='New Cases')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da13a517",
   "metadata": {},
   "source": [
    "New cases also shows an increasing pattern throughout the year\n",
    "New cases shows upward shift then downwad shift(Compared to upward) and follow the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd16e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = px.line(full_new, x='Date', y=['Active'], \n",
    "               title='Active Cases')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70d78e53",
   "metadata": {},
   "source": [
    "Overall covid active cases still increasing in 2020\n",
    "Since aug active cases are more than 2.5M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed46e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking with selected country i.e India\n",
    "!pip install altair\n",
    "India = full_new[full_new['Country/Region'] == 'India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "base = alt.Chart(India).mark_bar().encode(\n",
    "    x='monthdate(Date):O',\n",
    ").properties(\n",
    "    width=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65bc89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "red=alt.value('#f54242')\n",
    "base.encode(y='confirmed').properties(title='Total Confirmed')|base.encode(y='deaths', color=red).properties(title='Total Deaths')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60263095",
   "metadata": {},
   "source": [
    "confirmed cases increasing since may months and it rapidly increasing at a constant rate\n",
    "death cases also shows the same pattern as confirmed \n",
    "confirmed cases in lakhs and deaths in thousands which means most confirmed cases are active "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "red=alt.value('#f54242')\n",
    "base.encode(y='recovered').properties(title='Total Recovered')|base.encode(y='Active', color=red).properties(title='Active')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84dbb47f",
   "metadata": {},
   "source": [
    "Since last of may sharp increase in no of recovered cases in india and keep on increasing it\n",
    "Since Apr Active cases also increasing and keep on increasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881672b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "red=alt.value('#f54242')\n",
    "base.encode(y='New cases').properties(title='New Cases Confirmed')|base.encode(y='New deaths', color=red).properties(title='New Deaths')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5019f6db",
   "metadata": {},
   "source": [
    "Since June new cases crossed 30,000 in India and keep on increasing \n",
    "Since July new deathhs crossed 600 and rising afterwards months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b85882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights from selected countries\n",
    "\n",
    "countries = ['US', 'India', 'China', 'Brazil', 'Germany', 'Turkey', 'Italy', 'United Kingdom', 'Russia']\n",
    "selected_countries = full_new[full_new['Country/Region'].isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a885b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dbd56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let’s create a circle chart to display the day wise New cases,\n",
    "\n",
    "\n",
    "alt.Chart(selected_countries).mark_circle().encode(\n",
    "    x='monthdate(Date):O',\n",
    "    y='Country/Region',\n",
    "    color='Country/Region',\n",
    "    size=alt.Size('New cases:Q',\n",
    "        scale=alt.Scale(range=[0, 1000]),\n",
    "        legend=alt.Legend(title='Daily new cases')\n",
    "    ) \n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a060744",
   "metadata": {},
   "source": [
    "Brazil, India new cases rising since may while in US increasing since Feb\n",
    "China new cases increased since beginning months and since march onwards new cases are are falling\n",
    "Beginning of the year new cases in germany is low but in march there will be a rise in new cases after that since aug slight increase in cases\n",
    "From the above graph we can see that the increase in new cases for selected contries,\n",
    " We can see that the rise in daily new cases in countries like India,Us,France and Spain where India has the maximum of 80,000 new cases reported\n",
    " In Turkey and Italy thoughout maintain same no of rise except few months there new cases will be constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s create a circle chart to display the day wise New death cases,\n",
    "\n",
    "\n",
    "alt.Chart(selected_countries).mark_circle().encode(\n",
    "    x='monthdate(Date):O',\n",
    "    y='Country/Region',\n",
    "    color='Country/Region',\n",
    "    size=alt.Size('New deaths:Q',\n",
    "        scale=alt.Scale(range=[0, 1000]),\n",
    "        legend=alt.Legend(title='Death Cases')\n",
    "    ) \n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c4c5ca7",
   "metadata": {},
   "source": [
    "Death cases increases significantly in Brazil,India,US  since may month\n",
    "Italy,UK death case increased in between mar to may\n",
    "Russia death cases slightly increased since may month but for turkey slight increase happend is between march and may ,aug and sep\n",
    "China death cases increased in jan to march and a significant increase in Apr half afterwards shows a constant low death cases compared to previous death cases\n",
    "Germany shows same death cases through out the year except in between mar and may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312bfa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s create a circle chart to display the day wise New recovered cases,\n",
    "\n",
    "\n",
    "alt.Chart(selected_countries).mark_circle().encode(\n",
    "    x='monthdate(Date):O',\n",
    "    y='Country/Region',\n",
    "    color='Country/Region',\n",
    "    size=alt.Size('New recovered:Q',\n",
    "        scale=alt.Scale(range=[0, 1000]),\n",
    "        legend=alt.Legend(title='Daily new cases')\n",
    "    ) \n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1e82ad2",
   "metadata": {},
   "source": [
    "Recovered cases with respect to each countries\n",
    "Since may india shows very good number of recovered cases which is increasing , brazil also follows the same pattern and Us somewhat showing similar kind of pattern\n",
    "China almost maintain same number of recovered cases throughout the year, Germany also follows same patternsin between march and may there is a slight increase \n",
    "Italy,Russia and Turkey almost flat line but for Russia slight constant increase since may, for turkey slight increase and decrease but almost maintain the same line . Italy shows some signicant increase in Apr and may all other months the same thing\n",
    "UK maintain same flat curve \n",
    "overall all countries shows significant or slight increase in recoverred cases , which means fight againist the covid is success and effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af84fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping different types of cases as per the date\n",
    "datewise=full_new.groupby([\"Date\"]).agg({\"confirmed\":'sum',\"recovered\":'sum',\"deaths\":'sum'})\n",
    "datewise[\"Days Since\"]=datewise.index-datewise.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Growth rate of Confirmed, Recovered and Death Cases\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=datewise[\"confirmed\"],\n",
    "                    mode='lines+markers',\n",
    "                    name='Confirmed Cases'))\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=datewise[\"recovered\"],\n",
    "                    mode='lines+markers',\n",
    "                    name='Recovered Cases'))\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=datewise[\"deaths\"],\n",
    "                    mode='lines+markers',\n",
    "                    name='Death Cases'))\n",
    "fig.update_layout(title=\"Growth of different types of cases\",\n",
    "                 xaxis_title=\"Date\",yaxis_title=\"Number of Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6299c253",
   "metadata": {},
   "source": [
    "From the above diagram covid confirmed cases are increasing since february\n",
    "since April recovery cases also gradually increasing \n",
    "death cases shows almost a flatline throughout the year, only slight increase\n",
    "Even though confirmed cases are increasing which is quite upsetting but most of them recovering and doesnt turn it in to out of hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593f3d",
   "metadata": {},
   "source": [
    "## Mortality and Recovered Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Mortality Rate and Recovery Rate\n",
    "datewise[\"Mortality Rate\"]=(datewise[\"deaths\"]/datewise[\"confirmed\"])*100\n",
    "datewise[\"Recovery Rate\"]=(datewise[\"recovered\"]/datewise[\"confirmed\"])*100\n",
    "datewise[\"Active Cases\"]=datewise[\"confirmed\"]-datewise[\"recovered\"]-datewise[\"deaths\"]\n",
    "datewise[\"Closed Cases\"]=datewise[\"recovered\"]+datewise[\"deaths\"]\n",
    "\n",
    "print(\"Average Mortality Rate\",datewise[\"Mortality Rate\"].mean())\n",
    "print(\"Median Mortality Rate\",datewise[\"Mortality Rate\"].median())\n",
    "print(\"Average Recovery Rate\",datewise[\"Recovery Rate\"].mean())\n",
    "print(\"Median Recovery Rate\",datewise[\"Recovery Rate\"].median())\n",
    "\n",
    "#Plotting Mortality and Recovery Rate \n",
    "fig = make_subplots(rows=2, cols=1,\n",
    "                   subplot_titles=(\"Recovery Rate\", \"Mortatlity Rate\"))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=datewise.index, y=(datewise[\"recovered\"]/datewise[\"confirmed\"])*100,name=\"Recovery Rate\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=datewise.index, y=(datewise[\"deaths\"]/datewise[\"confirmed\"])*100,name=\"Mortality Rate\"),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.update_layout(height=1000,legend=dict(x=-0.1,y=1.2,traceorder=\"normal\"))\n",
    "fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Recovery Rate\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Date\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Mortality Rate\", row=1, col=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8dbd3a7",
   "metadata": {},
   "source": [
    "Mortality rate = (Number of Death Cases / Number of Confirmed Cases) x 100\n",
    "Recovery Rate= (Number of Recoverd Cases / Number of Confirmed Cases) x 100\n",
    "In the beginning of 2020 recovery is low, then gradually increased and low down\n",
    "Since April gradually increasing , which means everyone overcoming the covid-19\n",
    "Same as recovered cases beginning of 2020, mortality rate was decreasing but since march to may abruptly increased\n",
    "Since may it falldown which means recovery rate is increased and precautions and struggle againist covid was success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425b725",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4141821a",
   "metadata": {},
   "source": [
    "We can't do data Feature Selection , because its a regression analysis. so for the better performance will consider all values for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611b058",
   "metadata": {},
   "source": [
    "# Prediction using Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab177a9",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datewise[\"Days Since\"]=datewise.index - datewise.index[0]\n",
    "datewise[\"Days Since\"]=datewise[\"Days Since\"].dt.days\n",
    "\n",
    "# Splitting the data\n",
    "\n",
    "train_ml=datewise.iloc[ : int(datewise.shape[0]*0.95)]\n",
    "valid_ml=datewise.iloc[int(datewise.shape[0]*0.95) : ]\n",
    "model_scores=[]\n",
    "\n",
    "#Fitting\n",
    "\n",
    "lin_reg=LinearRegression(normalize=True)\n",
    "lin_reg.fit(np.array(train_ml[\"Days Since\"]).reshape(-1,1),np.array(train_ml[\"confirmed\"]).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling\n",
    "\n",
    "prediction_valid_linreg=lin_reg.predict(np.array(valid_ml[\"Days Since\"]).reshape(-1,1))\n",
    "\n",
    "model_scores.append(np.sqrt(mean_squared_error(valid_ml[\"confirmed\"],prediction_valid_linreg)))\n",
    "print(\"Root Mean Square Error for Linear Regression: \",np.sqrt(mean_squared_error(valid_ml[\"confirmed\"],prediction_valid_linreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,6))\n",
    "prediction_linreg=lin_reg.predict(np.array(datewise[\"Days Since\"]).reshape(-1,1))\n",
    "linreg_output=[]\n",
    "for i in range(prediction_linreg.shape[0]):\n",
    "    linreg_output.append(prediction_linreg[i][0])\n",
    "\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=datewise[\"confirmed\"],\n",
    "                    mode='lines+markers',name=\"Train Data for Confirmed Cases\"))\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=linreg_output,\n",
    "                    mode='lines',name=\"Linear Regression Best Fit Line\",\n",
    "                    line=dict(color='black', dash='dot')))\n",
    "fig.update_layout(title=\"Confirmed Cases Linear Regression Prediction\",\n",
    "                 xaxis_title=\"Date\",yaxis_title=\"Confirmed Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859fdf6c",
   "metadata": {},
   "source": [
    "### Prediction for next 30 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd857735",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date=[]\n",
    "new_prediction_lr=[]\n",
    "\n",
    "for i in range(1,30):\n",
    "    new_date.append(datewise.index[-1]+timedelta(days=i))\n",
    "    new_prediction_lr.append(lin_reg.predict(np.array(datewise[\"Days Since\"].max()+i).reshape(-1,1))[0][0])\n",
    "\n",
    "    \n",
    "    pd.set_option(\"display.float_format\",lambda x: '%.f'%x)\n",
    "    model_predictions=pd.DataFrame(zip(new_date,new_prediction_lr,),columns=[\"Dates\",\"LR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a7b95",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "train_ml=datewise.iloc[:int(datewise.shape[0]*0.95)]\n",
    "valid_ml=datewise.iloc[int(datewise.shape[0]*0.95):]\n",
    "\n",
    "poly = PolynomialFeatures(degree = 8) \n",
    "train_poly=poly.fit_transform(np.array(train_ml[\"Days Since\"]).reshape(-1,1))\n",
    "valid_poly=poly.fit_transform(np.array(valid_ml[\"Days Since\"]).reshape(-1,1))\n",
    "y=train_ml[\"confirmed\"]\n",
    "\n",
    "linreg=LinearRegression(normalize=True)\n",
    "linreg.fit(train_poly,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138505dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_poly=linreg.predict(valid_poly)\n",
    "rmse_poly=np.sqrt(mean_squared_error(valid_ml[\"confirmed\"],prediction_poly))\n",
    "model_scores.append(rmse_poly)\n",
    "print(\"Root Mean Squared Error for Polynomial Regression: \",rmse_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b829ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data=poly.fit_transform(np.array(datewise[\"Days Since\"]).reshape(-1,1))\n",
    "plt.figure(figsize=(11,6))\n",
    "predictions_poly=linreg.predict(comp_data)\n",
    "\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=datewise[\"confirmed\"],\n",
    "                    mode='lines+markers',name=\"Train Data for Confirmed Cases\"))\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=predictions_poly,\n",
    "                    mode='lines',name=\"Polynomial Regression Best Fit\",\n",
    "                    line=dict(color='black', dash='dot')))\n",
    "fig.update_layout(title=\"Confirmed Cases Polynomial Regression Prediction\",\n",
    "                 xaxis_title=\"Date\",yaxis_title=\"Confirmed Cases\",\n",
    "                 legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d35bea",
   "metadata": {},
   "source": [
    "## Prediction for next 30 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction_poly=[]\n",
    "for i in range(1,31):\n",
    "    new_date_poly=poly.fit_transform(np.array(datewise[\"Days Since\"].max()+i).reshape(-1,1))\n",
    "    new_prediction_poly.append(linreg.predict(new_date_poly)[0])\n",
    "    \n",
    "    pd.set_option(\"display.float_format\",lambda x: '%.f'%x)\n",
    "    model_predictions=pd.DataFrame(zip(new_date,new_prediction_poly),columns=[\"Dates\",\"POLY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b543ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b766960",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "datewise[\"Days Since\"]=datewise.index-datewise.index[0]\n",
    "datewise[\"Days Since\"]=datewise[\"Days Since\"].dt.days\n",
    "\n",
    "train_ml=datewise.iloc[:int(datewise.shape[0]*0.95)]\n",
    "valid_ml=datewise.iloc[int(datewise.shape[0]*0.95):]\n",
    "model_scores=[]\n",
    "\n",
    "svm=SVR(C=1,degree=5,kernel='poly',epsilon=0.001)\n",
    "\n",
    "svm.fit(np.array(train_ml[\"Days Since\"]).reshape(-1,1),np.array(train_ml[\"confirmed\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c05367",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_valid_svm=svm.predict(np.array(valid_ml[\"Days Since\"]).reshape(-1,1))\n",
    "\n",
    "model_scores.append(np.sqrt(mean_squared_error(valid_ml[\"confirmed\"],prediction_valid_svm)))\n",
    "print(\"Root Mean Square Error for Support Vectore Machine: \",np.sqrt(mean_squared_error(valid_ml[\"confirmed\"],prediction_valid_svm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8604f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,6))\n",
    "prediction_linreg=lin_reg.predict(np.array(datewise[\"Days Since\"]).reshape(-1,1))\n",
    "linreg_output=[]\n",
    "for i in range(prediction_linreg.shape[0]):\n",
    "    linreg_output.append(prediction_linreg[i][0])\n",
    "\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=datewise[\"confirmed\"],\n",
    "                    mode='lines+markers',name=\"Train Data for Confirmed Cases\"))\n",
    "fig.add_trace(go.Scatter(x=datewise.index, y=linreg_output,\n",
    "                    mode='lines',name=\"Best Fit Line\",\n",
    "                    line=dict(color='black', dash='dot')))\n",
    "fig.update_layout(title=\"Confirmed Cases  Regression Prediction\",\n",
    "                 xaxis_title=\"Date\",yaxis_title=\"Confirmed Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f17dff",
   "metadata": {},
   "source": [
    "## Prediction for next 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_date=[]\n",
    "new_prediction_svm=[]\n",
    "\n",
    "for i in range(1,30):\n",
    "    new_date.append(datewise.index[-1]+timedelta(days=i))\n",
    "    new_prediction_svm.append(svm.predict(np.array(datewise[\"Days Since\"].max()+i).reshape(-1,1))[0])\n",
    "\n",
    "    \n",
    "    pd.set_option(\"display.float_format\",lambda x: '%.f'%x)\n",
    "    model_predictions=pd.DataFrame(zip(new_date,new_prediction_svm),columns=[\"Dates\",\"SVM\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_predictions.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa0d39",
   "metadata": {},
   "source": [
    "# ARIMA MODEL"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e994008e",
   "metadata": {},
   "source": [
    "ARIMA, abbreviated for 'Auto Regressive Integrated Moving Average', is a class of models that 'demonstrates' a given time series based on its previous values: its lags and the lagged errors in forecasting, so that equation can be utilized in order to forecast future values.\n",
    "The 'p' is the order of the 'AR' (Auto-Regressive) term, which means that the number of lags of Y to be utilized as predictors. At the same time, 'q' is the order of the 'MA' (Moving Average) term, which means that the number of lagged forecast errors should be used in the ARIMA Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881540a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import *\n",
    "import statsmodels.api as sm #for ARIMA and SARIMAX\n",
    "import datetime\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller #adfuller stands for Augmented Dickey-Fuller unit root test.\n",
    "\n",
    "#The function find mean and standard deviation of the series and and performs augmented dickey fuller test.\n",
    "#returns pvale .. The samaller the pvalue more stationary is the series.\n",
    "\n",
    "def test_stationarity(timeseries, window = 15, cutoff = 0.01):\n",
    "    rolmean = timeseries.rolling(window).mean()\n",
    "    rolstd = timeseries.rolling(window).std()\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC',)\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    pvalue = dftest[1]\n",
    "    if pvalue < cutoff:\n",
    "        print('p-value = %.4f. The series is likely stationary.' % pvalue)\n",
    "    else:\n",
    "        print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n",
    "  \n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a94d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(full_new['confirmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024920f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_diff = full_new.confirmed - full_new.confirmed.shift(4)\n",
    "first_diff = first_diff.dropna(inplace = False)\n",
    "test_stationarity(first_diff, window = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(full_new.confirmed, ax=ax1, ) # using default value of lag\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(full_new.confirmed, ax=ax2) # using default value of lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(first_diff, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(first_diff, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sarimax_mod = sm.tsa.statespace.SARIMAX(full_new.confirmed, trend='n', order=(14,1,0)).fit()\n",
    "print(sarimax_mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "resid = sarimax_mod.resid #gives residual degree of freedom (mu, sigma, pvalue ... )\n",
    "print(normaltest(resid))\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "sns.distplot(resid ,fit = stats.norm, ax = ax0) # need to import scipy.stats\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = stats.norm.fit(resid)\n",
    "\n",
    "#Now plot the distribution using \n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residual distribution')\n",
    "\n",
    "\n",
    "# ACF and PACF\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(sarimax_mod.resid, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(sarimax_mod.resid, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_new"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d6f2871",
   "metadata": {},
   "source": [
    "The Augmented Dickey-Fuller (ADF) test's null hypothesis is that the time series is not stationary. Thus, if the ADF test's p-value is less than the significance level (0.05), then we will reject the null hypothesis and infer that the time series is definitely stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7401bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller  \n",
    "from numpy import log  \n",
    "import pandas as pd  \n",
    "  \n",
    "mydata = full_new \n",
    "  \n",
    "res = adfuller( mydata.confirmed.dropna())  \n",
    "print('Augmented Dickey-Fuller Statistic: %f' % res[0])  \n",
    "print('p-value: %f' % res[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd  \n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf  \n",
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "plt.rcParams.update({'figure.figsize' : (9,7), 'figure.dpi' : 120})  \n",
    " \n",
    "mydata = full_new \n",
    "\n",
    "df = full_new\n",
    "\n",
    "# The Genuine Series  \n",
    "fig, axes = plt.subplots(3, 2, sharex = True)  \n",
    "axes[0, 0].plot(df.confirmed); axes[0, 0].set_title('The Genuine Series')  \n",
    "plot_acf(df.confirmed, ax = axes[0, 1])  \n",
    "  \n",
    "# Order of Differencing: First  \n",
    "axes[1, 0].plot(df.confirmed.diff()); axes[1, 0].set_title('Order of Differencing: First')  \n",
    "plot_acf(df.confirmed.diff().dropna(), ax = axes[1, 1])  \n",
    "  \n",
    "# Order of Differencing: Second  \n",
    "axes[2, 0].plot(df.confirmed.diff().diff()); axes[2, 0].set_title('Order of Differencing: Second')  \n",
    "plot_acf(df.confirmed.diff().diff().dropna(), ax = axes[2, 1])  \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e65606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima.utils import ndiffs  \n",
    "import pandas as pd  \n",
    "  \n",
    "df = full_new \n",
    "X = df.confirmed  \n",
    "  \n",
    "# Augmented Dickey Fuller Test  \n",
    "adftest = ndiffs(X, test = 'adf')  \n",
    "  \n",
    "# KPSS Test  \n",
    "kpsstest = ndiffs(X, test = 'kpss')  \n",
    "  \n",
    "# PP Test  \n",
    "pptest = ndiffs(X, test = 'pp')  \n",
    "  \n",
    "print(\"ADF Test =\", adftest)  \n",
    "print(\"KPSS Test =\", kpsstest)  \n",
    "print(\"PP Test =\", pptest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd  \n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf  \n",
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})  \n",
    "  \n",
    "df = full_new \n",
    "  \n",
    "fig, axes = plt.subplots(1, 2, sharex = True)  \n",
    "axes[0].plot(df.confirmed.diff()); axes[0].set_title('Order of Differencing: First')  \n",
    "axes[1].set(ylim = (0,5))  \n",
    "plot_pacf(df.confirmed.diff().dropna(), ax = axes[1])  \n",
    "  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd  \n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf  \n",
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "plt.rcParams.update({'figure.figsize' : (9,3), 'figure.dpi' : 120})  \n",
    "  \n",
    "mydata = full_new \n",
    "  \n",
    "fig, axes = plt.subplots(1, 2, sharex = True)  \n",
    "axes[0].plot(mydata.confirmed.diff()); axes[0].set_title('Order of Differencing: First')  \n",
    "axes[1].set(ylim = (0, 1.2))  \n",
    "plot_acf(mydata.confirmed.diff().dropna(), ax = axes[1])  \n",
    "  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f05f1114",
   "metadata": {},
   "source": [
    "Sometimes, a situation may occur where the series is slightly under-differenced, and differencing it one time extra makes the series somewhat over-differenced. In such cases, we have to add one or multiple additional Auto-Regressive (AR) Terms for the slightly under-differenced Time Series and add an extra Moving Average (MA) Term for the slightly over-differenced Time Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a7335",
   "metadata": {},
   "source": [
    "# Building the ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfcc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd  \n",
    " \n",
    "\n",
    "mydata = full_new \n",
    "  \n",
    "# Creating ARIMA model  \n",
    "mymodel = ARIMA(full_new.confirmed, order = (0, 1, 0))  \n",
    "modelfit = mymodel.fit()  \n",
    "print(modelfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10681149",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0482ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd  \n",
    "  \n",
    "\n",
    "\n",
    "mydata = full_new \n",
    "  \n",
    "# Creating ARIMA model  \n",
    "mymodel = ARIMA(full_new.confirmed, order = (2, 2, 2))  \n",
    "modelfit = mymodel.fit()  \n",
    "print(modelfit.summary())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install statsmodels --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b58140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd  \n",
    "from statsmodels.tsa.arima_model import ARIMA  \n",
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "plt.rcParams.update({'figure.figsize' : (9,3), 'figure.dpi' : 120})  \n",
    "  \n",
    "\n",
    "mydata = full_new \n",
    "  \n",
    "# Creating ARIMA model  \n",
    "mymodel = ARIMA(full_new.confirmed, order = (0, 1, 0)) \n",
    "modelfit = mymodel.fit(disp = 0)  \n",
    "  \n",
    "# Actual vs Fitted  \n",
    "modelfit.plot_predict(dynamic = False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7f1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6b6efb1",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f393ea85",
   "metadata": {},
   "source": [
    "In this project,machine learning are used to observe everyday behaviour along,with the prediction of future reachability of the COVID-2019 across the nation by utilizing the real-time information from the Johns Hopkins dashboard.\n",
    "US,Brazil,UK,Italy,India most of death cases reported from here . so these countries should seriously take care about their people and strengthen their health department and activities\n",
    "Brazil,US,India,Russia,Mexico most recovered cases are from these countries they have to go with same activites for next few months for a stable scenario\n",
    "US,Brazil,India,Russia,Peru still a lot of confirmed cases and active cases happening these places. They should seriously take necessary actions to prevent covid and implant Lockdown,Quarentine and much more things and more over these countries implant vaccination compulsory .\n",
    "Here we have utalised 3 types of machine learning algorithms,ie,Linear Regression, Polynomial Regression and Support Vector Machine learning algorithm.The results show that polynomial regression (PR) yielded a minimum root mean square error (RMSE) score over other approaches in forecasting the COVID-19 transmission.However, if the spread follows the predicted trend of the PR model then it would lead to huge loss of lives as it presents the exponential growth of the transmission worldwide.\n",
    "The world is under the grasp of SARS-CoV2 (COVID-19) virus. Early prediction of the transmission can help to take necessary actions.As observed from China, this growth of the COVID-19 can be reduced and quenched by reducing the number of susceptible individuals from the infected individuals. This is achievable by becoming unsocial and following the lockdown initiative with discipline.\n",
    "Social Distancing. The logic here is, the virus can’t infect bodies if it cannot find bodies to infect!\n",
    "World Leaders in all affected countries announced quarantines and lock-downs to keep their folks safe and away from anything or anyone that could infect them, all big social events were postponed and all major sports leagues cancelled as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c13ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
